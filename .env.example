# Environment variables
# Copy to .env and change passwords before deployment

# Application
APP_NAME=whoisalice
APP_VERSION=0.1.0
APP_HOST=0.0.0.0
APP_PORT=8000
# CORS: in production set allowed origins (comma-separated), e.g. https://app.example.com
CORS_ORIGINS=*

# Database
POSTGRES_HOST=database
POSTGRES_PORT=5432
POSTGRES_DB=whoisalice
POSTGRES_USER=whoisalice
POSTGRES_PASSWORD=changeme_strong_password

# RabbitMQ Configuration
# These credentials will be used by both RabbitMQ server and app/workers
# Default: guest/guest (change for production!)
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest

# Logging
LOG_LEVEL=INFO

# JWT Authentication
SECRET_KEY=your-secret-key-change-in-production-use-openssl-rand-hex-32
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Telegram Bot
TELEGRAM_BOT_TOKEN=your-bot-token-from-botfather

# File Storage (must match docker-compose: ./volumes/audio_uploads, ./volumes/audio_results)
AUDIO_UPLOAD_DIR=volumes/audio_uploads
AUDIO_RESULTS_DIR=volumes/audio_results
MAX_AUDIO_SIZE_MB=10

# HuggingFace Inference Providers (router) - Together AI as default
# Enable Together at https://hf.co/settings/inference-providers
HF_INFERENCE_ENDPOINT=https://router.huggingface.co
HF_PROVIDER=together
# Token: Fine-grained with "Make calls to Inference Providers"
# https://huggingface.co/settings/tokens
HUGGINGFACE_API_TOKEN=your-hf-token
# STT (unchanged)
HF_STT_MODEL=openai/whisper-large-v3
# TTS: "huggingface" (default) or "yandex"
TTS_PROVIDER=huggingface
# TTS (HuggingFace): use a model supported by your provider
HF_TTS_MODEL=microsoft/speecht5_tts
# TTS (Yandex SpeechKit): https://cloud.yandex.com/docs/speechkit
# Create API key in Yandex Cloud Console → IAM → Service accounts → Create API key
YANDEX_API_KEY=
# Не указывать при API-ключе сервисного аккаунта (каталог определяется по ключу)
YANDEX_FOLDER_ID=
YANDEX_TTS_VOICE=filipp
YANDEX_TTS_LANG=ru-RU
# Text: GLM-5 via Together (https://huggingface.co/zai-org/GLM-5?inference_provider=together)
HF_CHAT_MODEL=zai-org/GLM-5
# Image-to-text: Kimi-K2.5 via Together (https://huggingface.co/moonshotai/Kimi-K2.5?inference_provider=together)
HF_IMAGE_TO_TEXT_MODEL=moonshotai/Kimi-K2.5
